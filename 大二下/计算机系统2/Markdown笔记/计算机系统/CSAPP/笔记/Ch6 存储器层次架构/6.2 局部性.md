![[存储技术增长趋势.png]]
![[Gap.png]]
**Gap：存储墙——无法跨越的墙 Memory Board**
**假如程序从Disk中取数据，程序需要上千万个周期来完成，所以程序从Disk中取数据是极不合理的。**

**How to bridge the Gap? ——缓存**
可以提前把Disk数据存到DRAM里（main memory)
DRAM <- Disk 会快几个量级
还可以 Cache <-- DRAM，又快几个量级
**==每一个上层的存储层次都是下层的缓存——广义的缓存==**
**这就是<font color="#ff0000">局部性</font>**

## 局部性原理
程序倾向于使用==**最近一段时间**==，==**距离其较近地址**==的数据和指令。
**==时间局部性==:**  **最近被访问**的数据或指令在未来可能还会被访问
**==空间局部性==**:  **当前访问地址附近的区域**在不久还有可能被访问
**==经验总结==：有良好局部性的程序比局部性差的程序运行更快**
### **例子：数组访问**
`For(int i=0;i<100;i++) sum+=a[i];`
这个程序会频繁地访问 **sum 和 a[i]** 
- **时间局部性 temporal locality**：在短时间内对**sum**频繁访问，程序倾向于访问最近频繁被访问的数据
- **空间局部性 spatial locality**： **遍历数组 0->1->2->3** ，访问地址附近区域

### **一个经典的问题：为什么矩阵 按行访问 比 按列访问 效率更高？**
**空间局部性！** 

**根据空间局部性，按行访问程序会将行的元素放入cache，其他元素放在DRAM中**
如果你反其道而行，cache命中率为0，每次访问都会清空和置换cache，而一直在访问DRAM，享受不到cache的性能，所以时间就慢。

**==cache就是基于局部性原理设计的==**
